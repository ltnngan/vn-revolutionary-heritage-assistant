{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754cf7ff",
   "metadata": {},
   "source": [
    "Running with Kaggle environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c57876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 1. Cài đặt thư viện\n",
    "# ========================================================================\n",
    "\n",
    "!pip install -q torch torchvision transformers pillow numpy tqdm\n",
    "!pip install -q nltk rouge-score bert-score pycocoevalcap\n",
    "!pip install -q peft==0.7.1 pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a938a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 2. Import thư viện\n",
    "# ========================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from transformers import (\n",
    "    ViTModel, ViTImageProcessor,\n",
    "    AutoModel, AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from transformers.modeling_outputs import BaseModelOutput\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "\n",
    "# Metrics\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 3. Cấu hình\n",
    "# ========================================================================\n",
    "\n",
    "class Config:\n",
    "    # Đường dẫn\n",
    "    JSON_PATH = '/kaggle/input/dataset/vn-revolutionary-heritage-vqa.json'\n",
    "    IMAGE_BASE_PATH = '/kaggle/input/images'\n",
    "    OUTPUT_DIR = '/kaggle/working/vit-phobert-vit5-lora'\n",
    "    \n",
    "    # Model\n",
    "    VIT_MODEL = 'google/vit-base-patch16-224'\n",
    "    PHOBERT_MODEL = 'vinai/phobert-base'\n",
    "    VIT5_MODEL = 'VietAI/vit5-base'\n",
    "    \n",
    "    # Hyperparameters huấn luyện\n",
    "    BATCH_SIZE = 4\n",
    "    GRADIENT_ACCUMULATION = 4\n",
    "    NUM_EPOCHS = 20\n",
    "    MAX_GRAD_NORM = 1.0\n",
    "    \n",
    "    # LoRA\n",
    "    USE_LORA = True\n",
    "    LR_LORA = 1e-4\n",
    "    WARMUP_RATIO = 0.05\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    # LoRA config cho từng model\n",
    "    LORA_VIT_R = 16\n",
    "    LORA_VIT_ALPHA = 32\n",
    "    LORA_VIT_DROPOUT = 0.15\n",
    "    LORA_VIT_TARGET_MODULES = [\"query\", \"key\", \"value\"]\n",
    "    \n",
    "    LORA_PHOBERT_R = 16\n",
    "    LORA_PHOBERT_ALPHA = 32\n",
    "    LORA_PHOBERT_DROPOUT = 0.15\n",
    "    LORA_PHOBERT_TARGET_MODULES = [\"query\", \"key\", \"value\"]\n",
    "    \n",
    "    LORA_VIT5_R = 16\n",
    "    LORA_VIT5_ALPHA = 32\n",
    "    LORA_VIT5_DROPOUT = 0.15\n",
    "    LORA_VIT5_TARGET_MODULES = [\"q\", \"k\", \"v\"]\n",
    "    \n",
    "    # Chia dữ liệu\n",
    "    TRAIN_RATIO = 0.8\n",
    "    VAL_RATIO = 0.10\n",
    "    TEST_RATIO = 0.10\n",
    "    SEED = 42\n",
    "    \n",
    "    # Độ dài sequence\n",
    "    MAX_QUESTION_LEN = 128\n",
    "    MAX_ANSWER_LEN = 128\n",
    "    \n",
    "    # Kiến trúc model\n",
    "    HIDDEN_SIZE = 768\n",
    "    NUM_ATTENTION_HEADS = 8\n",
    "    FUSION_DROPOUT = 0.15\n",
    "    \n",
    "    # Tối ưu hóa\n",
    "    USE_FP16 = True\n",
    "    USE_GRADIENT_CHECKPOINTING = True\n",
    "    NUM_WORKERS = 2\n",
    "    PATIENCE = 3\n",
    "    \n",
    "    # Generation parameters tối ưu cho tiếng Việt\n",
    "    GEN_MAX_LENGTH = 128\n",
    "    GEN_MIN_LENGTH = 3\n",
    "    GEN_NUM_BEAMS = 3\n",
    "    GEN_NO_REPEAT_NGRAM = 2\n",
    "    GEN_LENGTH_PENALTY = 0.8\n",
    "    GEN_REPETITION_PENALTY = 1.2\n",
    "    \n",
    "    # Composite score weights cho early stopping\n",
    "    SCORE_WEIGHTS = {\n",
    "        'bleu': 0.30,\n",
    "        'bertscore_f1': 0.30,\n",
    "        'cider': 0.20,\n",
    "        'rougeL': 0.15,\n",
    "        'exact_match': 0.05\n",
    "    }\n",
    "    \n",
    "    # Differentiated learning rates\n",
    "    LR_VIT_MULTIPLIER = 1.0      # 1e-4\n",
    "    LR_PHOBERT_MULTIPLIER = 0.5  # 5e-5\n",
    "    LR_VIT5_MULTIPLIER = 0.3     # 3e-5\n",
    "    LR_FUSION_MULTIPLIER = 5.0   # 5e-4\n",
    "    \n",
    "    # Fusion strategy: \"gating\" hoặc \"downsample\"\n",
    "    FUSION_STRATEGY = \"gating\"\n",
    "    VISUAL_DOWNSAMPLE_TARGET = 49  # 196 -> 49 nếu dùng downsample\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 4. Phân đoạn từ tiếng Việt\n",
    "# ========================================================================\n",
    "\n",
    "class WordSegmenter:\n",
    "    \"\"\"Tách từ tiếng Việt bằng PyVi\"\"\"\n",
    "    _instance = None\n",
    "    \n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super().__new__(cls)\n",
    "            print(\"✓ Đã load PyVi tokenizer\")\n",
    "        return cls._instance\n",
    "    \n",
    "    def segment(self, text):\n",
    "        \"\"\"Tách từ văn bản tiếng Việt\"\"\"\n",
    "        try:\n",
    "            return ViTokenizer.tokenize(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Cảnh báo: Lỗi tách từ: {e}\")\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4057cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 5. Load dữ liệu \n",
    "# ========================================================================\n",
    "\n",
    "def validate_samples(samples, name=\"samples\"):\n",
    "    \"\"\"Validate quality của samples\"\"\"\n",
    "    print(f\"\\nValidating {name}...\")\n",
    "    \n",
    "    valid_samples = []\n",
    "    issues = {\n",
    "        'empty_question': 0,\n",
    "        'empty_answer': 0,\n",
    "        'too_short_answer': 0,\n",
    "        'missing_image': 0\n",
    "    }\n",
    "    \n",
    "    for sample in samples:\n",
    "        # Check question\n",
    "        if not sample.get('question') or len(sample['question'].strip()) < 3:\n",
    "            issues['empty_question'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Check answer exists\n",
    "        if not sample.get('answer') or len(sample['answer'].strip()) < 2:\n",
    "            issues['empty_answer'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Check answer không quá ngắn (filter \"Có\", \"Không\", etc.)\n",
    "        answer_words = sample['answer'].strip().split()\n",
    "        if len(answer_words) < 2:\n",
    "            issues['too_short_answer'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Check image exists\n",
    "        if not os.path.exists(sample['image_path']):\n",
    "            issues['missing_image'] += 1\n",
    "            continue\n",
    "        \n",
    "        valid_samples.append(sample)\n",
    "    \n",
    "    # In report\n",
    "    print(f\"  Total samples: {len(samples)}\")\n",
    "    print(f\"  Valid samples: {len(valid_samples)}\")\n",
    "    if sum(issues.values()) > 0:\n",
    "        print(f\"  Issues found:\")\n",
    "        for issue_type, count in issues.items():\n",
    "            if count > 0:\n",
    "                print(f\"    - {issue_type}: {count}\")\n",
    "    \n",
    "    return valid_samples\n",
    "\n",
    "def load_and_prepare_data(json_path, image_base_path):\n",
    "    \"\"\"Load dữ liệu và chia theo ảnh để tránh data leakage\"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    image_groups = {}\n",
    "    \n",
    "    # Nhóm các QA theo ảnh\n",
    "    for item in data:\n",
    "        name = item.get('name', '')\n",
    "        location = item.get('location_after', item.get('location_before', ''))\n",
    "        \n",
    "        for img_data in item.get('images', []):\n",
    "            img_path = os.path.join(image_base_path, img_data['image'])\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "            \n",
    "            img_key = img_data['image']\n",
    "            if img_key not in image_groups:\n",
    "                image_groups[img_key] = []\n",
    "            \n",
    "            for qa in img_data.get('qas', []):\n",
    "                if not qa.get('answer') or len(qa['answer'].strip()) < 2:\n",
    "                    continue\n",
    "                \n",
    "                image_groups[img_key].append({\n",
    "                    'image_path': img_path,\n",
    "                    'question': qa['question'],\n",
    "                    'answer': qa['answer'],\n",
    "                    'site_name': name,\n",
    "                    'location': location,\n",
    "                    'image_key': img_key\n",
    "                })\n",
    "    \n",
    "    # Chia dữ liệu theo ảnh\n",
    "    image_keys = list(image_groups.keys())\n",
    "    np.random.seed(config.SEED)\n",
    "    np.random.shuffle(image_keys)\n",
    "    \n",
    "    n_images = len(image_keys)\n",
    "    n_test = int(n_images * config.TEST_RATIO)\n",
    "    n_val = int(n_images * config.VAL_RATIO)\n",
    "    \n",
    "    test_keys = image_keys[:n_test]\n",
    "    val_keys = image_keys[n_test:n_test+n_val]\n",
    "    train_keys = image_keys[n_test+n_val:]\n",
    "    \n",
    "    # Lấy samples\n",
    "    train_samples = [s for key in train_keys for s in image_groups[key]]\n",
    "    val_samples = [s for key in val_keys for s in image_groups[key]]\n",
    "    test_samples = [s for key in test_keys for s in image_groups[key]]\n",
    "    \n",
    "    np.random.shuffle(train_samples)\n",
    "    \n",
    "    train_samples = validate_samples(train_samples, \"train\")\n",
    "    val_samples = validate_samples(val_samples, \"val\")\n",
    "    test_samples = validate_samples(test_samples, \"test\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Chia dữ liệu theo ảnh (sau khi validate):\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Ảnh     - Train: {len(train_keys):4d} | Val: {len(val_keys):4d} | Test: {len(test_keys):4d}\")\n",
    "    print(f\"Samples - Train: {len(train_samples):4d} | Val: {len(val_samples):4d} | Test: {len(test_samples):4d}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Lưu test samples\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "    with open(os.path.join(config.OUTPUT_DIR, \"test_samples.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(test_samples, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return train_samples, val_samples, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e575f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 6. Dataset\n",
    "# ========================================================================\n",
    "\n",
    "class HeritageVQADataset(Dataset):\n",
    "    \"\"\"Dataset cho VQA di sản Việt Nam\"\"\"\n",
    "    def __init__(self, samples, vit_processor, phobert_tokenizer, vit5_tokenizer, segmenter):\n",
    "        self.samples = samples\n",
    "        self.vit_processor = vit_processor\n",
    "        self.phobert_tokenizer = phobert_tokenizer\n",
    "        self.vit5_tokenizer = vit5_tokenizer\n",
    "        self.segmenter = segmenter\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load ảnh\n",
    "        try:\n",
    "            image = Image.open(sample['image_path']).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi load ảnh {sample['image_path']}: {e}\")\n",
    "            image = Image.new('RGB', (224, 224), color='gray')\n",
    "        \n",
    "        # Xử lý ảnh cho ViT\n",
    "        pixel_values = self.vit_processor(images=image, return_tensors='pt')['pixel_values'].squeeze(0)\n",
    "        \n",
    "        # Tách từ câu hỏi cho PhoBERT\n",
    "        question = self.segmenter.segment(sample['question'])\n",
    "        \n",
    "        # Tokenize câu hỏi\n",
    "        question_enc = self.phobert_tokenizer(\n",
    "            question,\n",
    "            max_length=config.MAX_QUESTION_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize câu trả lời\n",
    "        answer_enc = self.vit5_tokenizer(\n",
    "            sample['answer'],\n",
    "            max_length=config.MAX_ANSWER_LEN,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'question_input_ids': question_enc['input_ids'].squeeze(0),\n",
    "            'question_attention_mask': question_enc['attention_mask'].squeeze(0),\n",
    "            'answer_input_ids': answer_enc['input_ids'].squeeze(0),\n",
    "            'answer_attention_mask': answer_enc['attention_mask'].squeeze(0),\n",
    "            'answer_text': sample['answer'],\n",
    "            'question_text': sample['question'],  \n",
    "            'image_path': sample['image_path']     \n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Gộp batch\"\"\"\n",
    "    return {\n",
    "        'pixel_values': torch.stack([item['pixel_values'] for item in batch]),\n",
    "        'question_input_ids': torch.stack([item['question_input_ids'] for item in batch]),\n",
    "        'question_attention_mask': torch.stack([item['question_attention_mask'] for item in batch]),\n",
    "        'answer_input_ids': torch.stack([item['answer_input_ids'] for item in batch]),\n",
    "        'answer_attention_mask': torch.stack([item['answer_attention_mask'] for item in batch]),\n",
    "        'answer_text': [item['answer_text'] for item in batch],\n",
    "        'question_text': [item['question_text'] for item in batch],  \n",
    "        'image_path': [item['image_path'] for item in batch]         \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 7. Module Fusion \n",
    "# ========================================================================\n",
    "\n",
    "class CrossModalAttention(nn.Module):\n",
    "    \"\"\"Cross-attention giữa visual và text\"\"\"\n",
    "    def __init__(self, hidden_size, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, key_value, key_padding_mask=None):\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            query, key_value, key_value,\n",
    "            key_padding_mask=key_padding_mask\n",
    "        )\n",
    "        return self.norm(query + self.dropout(attn_output))\n",
    "\n",
    "class FusionModule(nn.Module):\n",
    "    \"\"\"Kết hợp 2 chiều giữa visual và text với Gating - ĐÃ CẢI TIẾN\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.strategy = config.FUSION_STRATEGY\n",
    "        \n",
    "        # Visual attend to Question\n",
    "        self.v2q_attention = CrossModalAttention(\n",
    "            config.HIDDEN_SIZE, config.NUM_ATTENTION_HEADS, config.FUSION_DROPOUT\n",
    "        )\n",
    "        # Question attend to Visual\n",
    "        self.q2v_attention = CrossModalAttention(\n",
    "            config.HIDDEN_SIZE, config.NUM_ATTENTION_HEADS, config.FUSION_DROPOUT\n",
    "        )\n",
    "        \n",
    "        if self.strategy == \"gating\":\n",
    "            self.gate = nn.Sequential(\n",
    "                nn.Linear(config.HIDDEN_SIZE * 2, config.HIDDEN_SIZE),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(config.FUSION_DROPOUT),\n",
    "                nn.Linear(config.HIDDEN_SIZE, 1),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "            print(\"✓ Fusion: Gating mechanism enabled\")\n",
    "        \n",
    "        elif self.strategy == \"downsample\":\n",
    "            # Downsample từ 196 -> 49 tokens\n",
    "            self.visual_downsample = nn.Sequential(\n",
    "                nn.Conv1d(config.HIDDEN_SIZE, config.HIDDEN_SIZE, \n",
    "                         kernel_size=2, stride=2),  # 196 -> 98\n",
    "                nn.ReLU(),\n",
    "                nn.Conv1d(config.HIDDEN_SIZE, config.HIDDEN_SIZE, \n",
    "                         kernel_size=2, stride=2)   # 98 -> 49\n",
    "            )\n",
    "            print(\"✓ Fusion: Visual downsampling enabled (196 -> 49)\")\n",
    "        \n",
    "        # Projection\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(config.HIDDEN_SIZE, config.HIDDEN_SIZE),\n",
    "            nn.LayerNorm(config.HIDDEN_SIZE),\n",
    "            nn.Dropout(config.FUSION_DROPOUT)\n",
    "        )\n",
    "    \n",
    "    def forward(self, visual_features, question_features, question_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            visual_features: [batch, 196, 768] từ ViT\n",
    "            question_features: [batch, seq_len, 768] từ PhoBERT\n",
    "            question_mask: [batch, seq_len]\n",
    "        Returns:\n",
    "            fused: [batch, N, 768] where N depends on strategy\n",
    "        \"\"\"\n",
    "        if self.strategy == \"downsample\":\n",
    "            # visual_features: [batch, 196, 768]\n",
    "            vis_transposed = visual_features.transpose(1, 2)  # [batch, 768, 196]\n",
    "            vis_downsampled = self.visual_downsample(vis_transposed)  # [batch, 768, 49]\n",
    "            visual_features = vis_downsampled.transpose(1, 2)  # [batch, 49, 768]\n",
    "        \n",
    "        question_padding_mask = (question_mask == 0)\n",
    "        \n",
    "        # Cross-attention\n",
    "        attended_question = self.v2q_attention(\n",
    "            query=question_features,\n",
    "            key_value=visual_features,\n",
    "            key_padding_mask=None\n",
    "        )\n",
    "        \n",
    "        attended_visual = self.q2v_attention(\n",
    "            query=visual_features,\n",
    "            key_value=question_features,\n",
    "            key_padding_mask=question_padding_mask\n",
    "        )\n",
    "        \n",
    "        # ===== APPLY GATING NẾU CẦN =====\n",
    "        if self.strategy == \"gating\":\n",
    "            # Compute gate weight\n",
    "            vis_pooled = attended_visual.mean(dim=1)  # [batch, 768]\n",
    "            q_pooled = attended_question.mean(dim=1)  # [batch, 768]\n",
    "            gate_input = torch.cat([vis_pooled, q_pooled], dim=-1)  # [batch, 1536]\n",
    "            gate_weight = self.gate(gate_input)  # [batch, 1]\n",
    "            \n",
    "            # Apply gate\n",
    "            attended_visual = attended_visual * gate_weight.unsqueeze(1)\n",
    "            attended_question = attended_question * (1 - gate_weight.unsqueeze(1))\n",
    "        \n",
    "        # Concat và project\n",
    "        fused = torch.cat([attended_visual, attended_question], dim=1)\n",
    "        return self.projection(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 8. Custom ViT với LoRA\n",
    "# ========================================================================\n",
    "\n",
    "class ViTWithLoRA(nn.Module):\n",
    "    \"\"\"ViT với LoRA adapters tự implement\"\"\"\n",
    "    def __init__(self, vit_model, r=8, alpha=16, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vit = vit_model\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / r\n",
    "\n",
    "        self.lora_layers = nn.ModuleDict()\n",
    "        \n",
    "        # Thêm LoRA cho query & value của tất cả attention layers\n",
    "        self.lora_layers = nn.ModuleDict()\n",
    "        \n",
    "        for i, layer in enumerate(self.vit.encoder.layer):\n",
    "            # LoRA cho Query\n",
    "            query_layer = layer.attention.attention.query\n",
    "            in_features = query_layer.in_features\n",
    "            out_features = query_layer.out_features\n",
    "            \n",
    "            self.lora_layers[f'layer_{i}_query_A'] = nn.Linear(in_features, r, bias=False)\n",
    "            self.lora_layers[f'layer_{i}_query_B'] = nn.Linear(r, out_features, bias=False)\n",
    "\n",
    "            key_layer = layer.attention.attention.key\n",
    "\n",
    "            self.lora_layers[f'layer_{i}_key_A'] = nn.Linear(in_features, r, bias=False)  \n",
    "            self.lora_layers[f'layer_{i}_key_B'] = nn.Linear(r, out_features, bias=False)  \n",
    "            \n",
    "            # LoRA cho Value\n",
    "            self.lora_layers[f'layer_{i}_value_A'] = nn.Linear(in_features, r, bias=False)\n",
    "            self.lora_layers[f'layer_{i}_value_B'] = nn.Linear(r, out_features, bias=False)\n",
    "            \n",
    "            # Khởi tạo weights\n",
    "            nn.init.kaiming_uniform_(self.lora_layers[f'layer_{i}_query_A'].weight, a=math.sqrt(5))\n",
    "            nn.init.zeros_(self.lora_layers[f'layer_{i}_query_B'].weight)\n",
    "            nn.init.kaiming_uniform_(self.lora_layers[f'layer_{i}_key_A'].weight, a=math.sqrt(5))  \n",
    "            nn.init.zeros_(self.lora_layers[f'layer_{i}_key_B'].weight)\n",
    "            nn.init.kaiming_uniform_(self.lora_layers[f'layer_{i}_value_A'].weight, a=math.sqrt(5))\n",
    "            nn.init.zeros_(self.lora_layers[f'layer_{i}_value_B'].weight)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Đóng băng ViT gốc\n",
    "        for param in self.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        print(f\"ViT LoRA: r={r}, alpha={alpha}, {len(self.lora_layers)} adapters\")\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        \"\"\"Forward pass với LoRA\"\"\"\n",
    "        hooks = []\n",
    "        \n",
    "        def make_lora_hook(layer_idx, param_name):\n",
    "            def hook(module, input, output):\n",
    "                lora_A = self.lora_layers[f'layer_{layer_idx}_{param_name}_A']\n",
    "                lora_B = self.lora_layers[f'layer_{layer_idx}_{param_name}_B']\n",
    "                x = input[0]\n",
    "                lora_output = lora_B(lora_A(self.dropout(x))) * self.scaling\n",
    "                return output + lora_output\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks\n",
    "        for i, layer in enumerate(self.vit.encoder.layer):\n",
    "            h1 = layer.attention.attention.query.register_forward_hook(make_lora_hook(i, 'query'))\n",
    "            h2 = layer.attention.attention.key.register_forward_hook(make_lora_hook(i, 'key'))\n",
    "            h3 = layer.attention.attention.value.register_forward_hook(make_lora_hook(i, 'value'))\n",
    "            hooks.extend([h1, h2, h3])\n",
    "        \n",
    "        # Forward ViT\n",
    "        outputs = self.vit(pixel_values=pixel_values)\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def print_trainable_parameters(self):\n",
    "        \"\"\"In số params huấn luyện\"\"\"\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        all_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Trainable: {trainable_params:,} / {all_params:,} ({100*trainable_params/all_params:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251c6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 9. Model chính\n",
    "# ========================================================================\n",
    "\n",
    "class ViTPhoBERTViT5Model(nn.Module):\n",
    "    \"\"\"Model VQA: ViT + PhoBERT + ViT5 với LoRA\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Khởi tạo Model với LoRA\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Load pretrained models\n",
    "        print(\"Loading ViT...\")\n",
    "        vit_base = ViTModel.from_pretrained(config.VIT_MODEL)\n",
    "        \n",
    "        print(\"Loading PhoBERT...\")\n",
    "        self.phobert = AutoModel.from_pretrained(config.PHOBERT_MODEL)\n",
    "        \n",
    "        print(\"Loading ViT5...\")\n",
    "        self.vit5 = AutoModelForSeq2SeqLM.from_pretrained(config.VIT5_MODEL)\n",
    "        \n",
    "        # Áp dụng LoRA\n",
    "        if config.USE_LORA:\n",
    "            print(\"\\nÁp dụng LoRA...\")\n",
    "            \n",
    "            # Custom LoRA cho ViT\n",
    "            self.vit = ViTWithLoRA(\n",
    "                vit_base,\n",
    "                r=config.LORA_VIT_R,\n",
    "                alpha=config.LORA_VIT_ALPHA,\n",
    "                dropout=config.LORA_VIT_DROPOUT\n",
    "            )\n",
    "            self.vit.print_trainable_parameters()\n",
    "            \n",
    "            # PEFT LoRA cho PhoBERT\n",
    "            phobert_lora_config = LoraConfig(\n",
    "                r=config.LORA_PHOBERT_R,\n",
    "                lora_alpha=config.LORA_PHOBERT_ALPHA,\n",
    "                target_modules=config.LORA_PHOBERT_TARGET_MODULES,\n",
    "                lora_dropout=config.LORA_PHOBERT_DROPOUT,\n",
    "                bias=\"none\",\n",
    "                task_type=TaskType.FEATURE_EXTRACTION\n",
    "            )\n",
    "            self.phobert = get_peft_model(self.phobert, phobert_lora_config)\n",
    "            print(\"✓ PhoBERT LoRA\")\n",
    "            self.phobert.print_trainable_parameters()\n",
    "            \n",
    "            # PEFT LoRA cho ViT5\n",
    "            vit5_lora_config = LoraConfig(\n",
    "                r=config.LORA_VIT5_R,\n",
    "                lora_alpha=config.LORA_VIT5_ALPHA,\n",
    "                target_modules=config.LORA_VIT5_TARGET_MODULES,\n",
    "                lora_dropout=config.LORA_VIT5_DROPOUT,\n",
    "                bias=\"none\",\n",
    "                task_type=TaskType.SEQ_2_SEQ_LM\n",
    "            )\n",
    "            self.vit5 = get_peft_model(self.vit5, vit5_lora_config)\n",
    "            print(\"✓ ViT5 LoRA\")\n",
    "            self.vit5.print_trainable_parameters()\n",
    "        else:\n",
    "            self.vit = vit_base\n",
    "        \n",
    "        # Fusion module\n",
    "        print(\"\\nKhởi tạo Fusion...\")\n",
    "        self.fusion = FusionModule(config)\n",
    "        \n",
    "        # Projection đến ViT5\n",
    "        vit5_dim = self.vit5.config.d_model\n",
    "        self.fusion_to_vit5 = nn.Linear(config.HIDDEN_SIZE, vit5_dim)\n",
    "        \n",
    "        self.pad_token_id = self.vit5.config.pad_token_id or 0\n",
    "        \n",
    "        # Gradient checkpointing\n",
    "        if config.USE_GRADIENT_CHECKPOINTING:\n",
    "            self.vit5.gradient_checkpointing_enable()\n",
    "        \n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    def forward(self, pixel_values, question_input_ids, question_attention_mask, \n",
    "                answer_input_ids=None, answer_attention_mask=None):\n",
    "        batch_size = pixel_values.size(0)\n",
    "        \n",
    "        # Extract visual features từ ViT\n",
    "        vit_outputs = self.vit(pixel_values=pixel_values)\n",
    "        visual_features = vit_outputs.last_hidden_state[:, 1:, :]  # [batch, 196, 768]\n",
    "        \n",
    "        # Extract question features từ PhoBERT\n",
    "        phobert_outputs = self.phobert(\n",
    "            input_ids=question_input_ids,\n",
    "            attention_mask=question_attention_mask\n",
    "        )\n",
    "        question_features = phobert_outputs.last_hidden_state\n",
    "        \n",
    "        # Fusion\n",
    "        fused_features = self.fusion(visual_features, question_features, question_attention_mask)\n",
    "        fused_features = self.fusion_to_vit5(fused_features)\n",
    "        \n",
    "        # Tạo attention mask cho fused features\n",
    "        num_visual_tokens = fused_features.size(1) - question_attention_mask.size(1)\n",
    "        visual_mask = torch.ones(batch_size, num_visual_tokens, dtype=torch.long, device=fused_features.device)\n",
    "        fused_attention_mask = torch.cat([visual_mask, question_attention_mask], dim=1)\n",
    "        \n",
    "        # Wrap cho ViT5\n",
    "        encoder_outputs = BaseModelOutput(last_hidden_state=fused_features)\n",
    "        \n",
    "        if answer_input_ids is not None:\n",
    "            # Training mode\n",
    "            labels = answer_input_ids.clone()\n",
    "            labels[labels == self.pad_token_id] = -100\n",
    "            \n",
    "            outputs = self.vit5(\n",
    "                attention_mask=fused_attention_mask,\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                labels=labels,\n",
    "                return_dict=True\n",
    "            )\n",
    "            return outputs\n",
    "        else:\n",
    "            # inference mode\n",
    "            outputs = self.vit5.generate(\n",
    "                encoder_outputs=encoder_outputs,\n",
    "                attention_mask=fused_attention_mask,\n",
    "                max_length=self.config.GEN_MAX_LENGTH,\n",
    "                min_length=self.config.GEN_MIN_LENGTH,\n",
    "                num_beams=self.config.GEN_NUM_BEAMS,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=self.config.GEN_NO_REPEAT_NGRAM,\n",
    "                length_penalty=self.config.GEN_LENGTH_PENALTY,\n",
    "                repetition_penalty=self.config.GEN_REPETITION_PENALTY,\n",
    "                do_sample=False\n",
    "            )\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246dd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 10. Metrics\n",
    "# ========================================================================\n",
    "\n",
    "class VQAMetrics:\n",
    "    \"\"\"Tính toán metrics đánh giá VQA\"\"\"\n",
    "    def __init__(self):\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        self.smooth = SmoothingFunction()\n",
    "    \n",
    "    def compute_bleu(self, predictions, references):\n",
    "        \"\"\"Tính BLEU\"\"\"\n",
    "        scores = []\n",
    "        for pred, ref in zip(predictions, references):\n",
    "            pred_tokens = str(pred).lower().split()\n",
    "            ref_tokens = str(ref).lower().split()\n",
    "            try:\n",
    "                score = sentence_bleu([ref_tokens], pred_tokens, smoothing_function=self.smooth.method1)\n",
    "                scores.append(score)\n",
    "            except:\n",
    "                scores.append(0.0)\n",
    "        return scores\n",
    "    \n",
    "    def compute_rouge(self, predictions, references):\n",
    "        \"\"\"Tính ROUGE\"\"\"\n",
    "        r1, r2, rL = [], [], []\n",
    "        for pred, ref in zip(predictions, references):\n",
    "            try:\n",
    "                scores = self.rouge_scorer.score(str(ref).lower(), str(pred).lower())\n",
    "                r1.append(scores['rouge1'].fmeasure)\n",
    "                r2.append(scores['rouge2'].fmeasure)\n",
    "                rL.append(scores['rougeL'].fmeasure)\n",
    "            except:\n",
    "                r1.append(0.0)\n",
    "                r2.append(0.0)\n",
    "                rL.append(0.0)\n",
    "        return r1, r2, rL\n",
    "    \n",
    "    def compute_bertscore(self, predictions, references):\n",
    "        \"\"\"Tính BERTScore\"\"\"\n",
    "        try:\n",
    "            P, R, F1 = bert_score(\n",
    "                [str(p) for p in predictions], \n",
    "                [str(r) for r in references], \n",
    "                model_type='bert-base-multilingual-cased',\n",
    "                verbose=False,\n",
    "                device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "            )\n",
    "            return F1.mean().item()\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def compute_cider(self, predictions, references):\n",
    "        \"\"\"Tính CIDEr\"\"\"\n",
    "        try:\n",
    "            gts = {i: [str(r)] for i, r in enumerate(references)}\n",
    "            res = {i: [str(p)] for i, p in enumerate(predictions)}\n",
    "            cider_scorer = Cider()\n",
    "            score, _ = cider_scorer.compute_score(gts, res)\n",
    "            return score\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def compute_exact_match(self, predictions, references):\n",
    "        \"\"\"Tính Exact Match\"\"\"\n",
    "        matches = []\n",
    "        for pred, ref in zip(predictions, references):\n",
    "            pred_norm = str(pred).strip().lower()\n",
    "            ref_norm = str(ref).strip().lower()\n",
    "            matches.append(1.0 if pred_norm == ref_norm else 0.0)\n",
    "        return matches\n",
    "    \n",
    "    def compute_all(self, predictions, references):\n",
    "        \"\"\"Tính tất cả metrics\"\"\"\n",
    "        bleu = self.compute_bleu(predictions, references)\n",
    "        r1, r2, rL = self.compute_rouge(predictions, references)\n",
    "        bertscore = self.compute_bertscore(predictions, references)\n",
    "        cider = self.compute_cider(predictions, references)\n",
    "        exact_match = self.compute_exact_match(predictions, references)\n",
    "        \n",
    "        return {\n",
    "            'bleu': np.mean(bleu),\n",
    "            'rouge1': np.mean(r1),\n",
    "            'rouge2': np.mean(r2),\n",
    "            'rougeL': np.mean(rL),\n",
    "            'bertscore_f1': bertscore,\n",
    "            'cider': cider,\n",
    "            'exact_match': np.mean(exact_match)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d24448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 11. Trainer \n",
    "# ========================================================================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Huấn luyện model với differentiated LR và composite score\"\"\"\n",
    "    def __init__(self, model, train_loader, val_loader, vit5_tokenizer, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.vit5_tokenizer = vit5_tokenizer\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.optimizer = self._create_optimizer_with_grouped_lr()\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        num_training_steps = len(train_loader) * config.NUM_EPOCHS // config.GRADIENT_ACCUMULATION\n",
    "        num_warmup_steps = int(num_training_steps * config.WARMUP_RATIO)\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        \n",
    "        # Mixed precision\n",
    "        self.scaler = GradScaler() if config.USE_FP16 else None\n",
    "        \n",
    "        # Metrics\n",
    "        self.metrics_calculator = VQAMetrics()\n",
    "        \n",
    "        # Early stopping với composite score\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_bleu = 0.0\n",
    "        self.best_composite_score = 0.0 \n",
    "        self.patience_counter = 0\n",
    "        \n",
    "        # History\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.val_metrics_history = []\n",
    "    \n",
    "    def _create_optimizer_with_grouped_lr(self):\n",
    "        \"\"\"Tạo optimizer với LR khác nhau cho từng component\"\"\"\n",
    "        vit_lora_params = []\n",
    "        phobert_lora_params = []\n",
    "        vit5_lora_params = []\n",
    "        fusion_params = []\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if not param.requires_grad:\n",
    "                continue\n",
    "            \n",
    "            if 'vit.lora' in name:\n",
    "                vit_lora_params.append(param)\n",
    "            elif 'phobert' in name and 'lora' in name.lower():\n",
    "                phobert_lora_params.append(param)\n",
    "            elif 'vit5' in name and 'lora' in name.lower():\n",
    "                vit5_lora_params.append(param)\n",
    "            elif 'fusion' in name or 'fusion_to_vit5' in name:\n",
    "                fusion_params.append(param)\n",
    "        \n",
    "        param_groups = []\n",
    "        \n",
    "        if len(vit_lora_params) > 0:\n",
    "            param_groups.append({\n",
    "                'params': vit_lora_params, \n",
    "                'lr': self.config.LR_LORA * self.config.LR_VIT_MULTIPLIER,\n",
    "                'name': 'vit_lora'\n",
    "            })\n",
    "        \n",
    "        if len(phobert_lora_params) > 0:\n",
    "            param_groups.append({\n",
    "                'params': phobert_lora_params, \n",
    "                'lr': self.config.LR_LORA * self.config.LR_PHOBERT_MULTIPLIER,\n",
    "                'name': 'phobert_lora'\n",
    "            })\n",
    "        \n",
    "        if len(vit5_lora_params) > 0:\n",
    "            param_groups.append({\n",
    "                'params': vit5_lora_params, \n",
    "                'lr': self.config.LR_LORA * self.config.LR_VIT5_MULTIPLIER,\n",
    "                'name': 'vit5_lora'\n",
    "            })\n",
    "        \n",
    "        if len(fusion_params) > 0:\n",
    "            param_groups.append({\n",
    "                'params': fusion_params, \n",
    "                'lr': self.config.LR_LORA * self.config.LR_FUSION_MULTIPLIER,\n",
    "                'name': 'fusion'\n",
    "            })\n",
    "        \n",
    "        print(\"\\nDifferentiated Learning Rates:\")\n",
    "        for pg in param_groups:\n",
    "            print(f\"  {pg['name']:15s}: {pg['lr']:.2e} ({len(pg['params'])} param groups)\")\n",
    "        \n",
    "        return torch.optim.AdamW(\n",
    "            param_groups,\n",
    "            weight_decay=self.config.WEIGHT_DECAY\n",
    "        )\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Train 1 epoch\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{self.config.NUM_EPOCHS}')\n",
    "        \n",
    "        for step, batch in enumerate(pbar):\n",
    "            # Chuyển batch sang device\n",
    "            batch = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v \n",
    "                    for k, v in batch.items()}\n",
    "            \n",
    "            # Forward với mixed precision\n",
    "            with autocast(enabled=self.config.USE_FP16):\n",
    "                outputs = self.model(\n",
    "                    pixel_values=batch['pixel_values'],\n",
    "                    question_input_ids=batch['question_input_ids'],\n",
    "                    question_attention_mask=batch['question_attention_mask'],\n",
    "                    answer_input_ids=batch['answer_input_ids'],\n",
    "                    answer_attention_mask=batch['answer_attention_mask']\n",
    "                )\n",
    "                loss = outputs.loss / self.config.GRADIENT_ACCUMULATION\n",
    "            \n",
    "            # Backward\n",
    "            if self.scaler:\n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            \n",
    "            # Optimizer step với gradient accumulation\n",
    "            if (step + 1) % self.config.GRADIENT_ACCUMULATION == 0:\n",
    "                if self.scaler:\n",
    "                    self.scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.MAX_GRAD_NORM)\n",
    "                    self.optimizer.step()\n",
    "                \n",
    "                self.scheduler.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            # Cập nhật progress bar\n",
    "            total_loss += loss.item() * self.config.GRADIENT_ACCUMULATION\n",
    "            current_loss = total_loss / (step + 1)\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{current_loss:.4f}',\n",
    "                'lr': f'{self.scheduler.get_last_lr()[0]:.2e}'\n",
    "            })\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        self.train_losses.append(avg_loss)\n",
    "        return avg_loss\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, data_loader, desc='Đánh giá', return_details=False):\n",
    "        \"\"\"Đánh giá trên validation/test set\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_predictions = []\n",
    "        all_references = []\n",
    "        all_questions = []    \n",
    "        all_image_paths = [] \n",
    "        \n",
    "        for batch in tqdm(data_loader, desc=desc):\n",
    "            batch_device = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v \n",
    "                           for k, v in batch.items()}\n",
    "            \n",
    "            # Generate predictions\n",
    "            generated_ids = self.model(\n",
    "                pixel_values=batch_device['pixel_values'],\n",
    "                question_input_ids=batch_device['question_input_ids'],\n",
    "                question_attention_mask=batch_device['question_attention_mask']\n",
    "            )\n",
    "            \n",
    "            # Decode\n",
    "            predictions = self.vit5_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            all_predictions.extend(predictions)\n",
    "            all_references.extend(batch['answer_text'])\n",
    "            all_questions.extend(batch['question_text'])   \n",
    "            all_image_paths.extend(batch['image_path'])     \n",
    "            \n",
    "            # Tính loss\n",
    "            try:\n",
    "                outputs = self.model(\n",
    "                    pixel_values=batch_device['pixel_values'],\n",
    "                    question_input_ids=batch_device['question_input_ids'],\n",
    "                    question_attention_mask=batch_device['question_attention_mask'],\n",
    "                    answer_input_ids=batch_device['answer_input_ids'],\n",
    "                    answer_attention_mask=batch_device['answer_attention_mask']\n",
    "                )\n",
    "                total_loss += outputs.loss.item()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            del generated_ids\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Tính metrics\n",
    "        metrics = self.metrics_calculator.compute_all(all_predictions, all_references)\n",
    "        metrics['loss'] = total_loss / len(data_loader) if total_loss > 0 else 0.0\n",
    "        \n",
    "        if return_details:\n",
    "            return metrics, all_predictions, all_references, all_questions, all_image_paths\n",
    "        else:\n",
    "            return metrics, all_predictions, all_references\n",
    "    \n",
    "    def save_checkpoint(self, epoch, metrics, is_best=False):\n",
    "        \"\"\"Lưu checkpoint với error handling - ĐÃ CẢI TIẾN\"\"\"\n",
    "        checkpoint_dir = self.config.OUTPUT_DIR\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            # Lưu ViT Custom LoRA\n",
    "            vit_lora_path = os.path.join(checkpoint_dir, 'vit_lora.pt')\n",
    "            torch.save(\n",
    "                self.model.vit.lora_layers.state_dict(),\n",
    "                vit_lora_path\n",
    "            )\n",
    "            \n",
    "            # Lưu PhoBERT PEFT LoRA\n",
    "            phobert_path = os.path.join(checkpoint_dir, 'phobert_lora')\n",
    "            self.model.phobert.save_pretrained(phobert_path)\n",
    "            \n",
    "            # Lưu ViT5 PEFT LoRA\n",
    "            vit5_path = os.path.join(checkpoint_dir, 'vit5_lora')\n",
    "            self.model.vit5.save_pretrained(vit5_path)\n",
    "            \n",
    "            # Lưu Fusion và components khác\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'fusion': self.model.fusion.state_dict(),\n",
    "                'projection': self.model.fusion_to_vit5.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'scheduler': self.scheduler.state_dict(),\n",
    "                'metrics': metrics,\n",
    "                'config': vars(self.config),\n",
    "                'vit_lora_config': {\n",
    "                    'r': self.config.LORA_VIT_R,\n",
    "                    'alpha': self.config.LORA_VIT_ALPHA,\n",
    "                    'dropout': self.config.LORA_VIT_DROPOUT\n",
    "                }\n",
    "            }, checkpoint_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saving checkpoint: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "        \n",
    "        # Lưu best model\n",
    "        if is_best:\n",
    "            try:\n",
    "                import shutil\n",
    "                \n",
    "                shutil.copy(\n",
    "                    os.path.join(checkpoint_dir, 'vit_lora.pt'),\n",
    "                    os.path.join(checkpoint_dir, 'best_vit_lora.pt')\n",
    "                )\n",
    "                \n",
    "                for name in ['phobert_lora', 'vit5_lora']:\n",
    "                    src = os.path.join(checkpoint_dir, name)\n",
    "                    dst = os.path.join(checkpoint_dir, f'best_{name}')\n",
    "                    if os.path.exists(dst):\n",
    "                        shutil.rmtree(dst)\n",
    "                    shutil.copytree(src, dst)\n",
    "                \n",
    "                shutil.copy(\n",
    "                    os.path.join(checkpoint_dir, 'checkpoint.pt'),\n",
    "                    os.path.join(checkpoint_dir, 'best_checkpoint.pt')\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error saving best model: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Vòng lặp huấn luyện chính với composite score\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Bắt đầu huấn luyện với LoRA\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Thống kê model\n",
    "        total_params = sum(p.numel() for p in self.model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"\\nThống kê Model:\")\n",
    "        print(f\"  Tổng params:      {total_params:,}\")\n",
    "        print(f\"  Trainable params: {trainable_params:,}\")\n",
    "        print(f\"  Tỷ lệ trainable:  {100*trainable_params/total_params:.2f}%\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        for epoch in range(self.config.NUM_EPOCHS):\n",
    "            # Train\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics, val_preds, val_refs = self.evaluate(self.val_loader, desc='Validation')\n",
    "            self.val_losses.append(val_metrics['loss'])\n",
    "            self.val_metrics_history.append(val_metrics)\n",
    "            \n",
    "            composite_score = sum(\n",
    "                val_metrics[k] * self.config.SCORE_WEIGHTS[k]\n",
    "                for k in self.config.SCORE_WEIGHTS.keys()\n",
    "                if k in val_metrics\n",
    "            )\n",
    "            \n",
    "            # In kết quả\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Epoch {epoch+1}/{self.config.NUM_EPOCHS}:\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Train Loss:      {train_loss:.4f}\")\n",
    "            print(f\"Val Loss:        {val_metrics['loss']:.4f}\")\n",
    "            print(f\"Composite Score: {composite_score:.4f}\")  # ===== MỚI =====\n",
    "            print(f\"\\nMetrics:\")\n",
    "            print(f\"  BLEU:        {val_metrics['bleu']:.4f}\")\n",
    "            print(f\"  ROUGE-1:     {val_metrics['rouge1']:.4f}\")\n",
    "            print(f\"  ROUGE-2:     {val_metrics['rouge2']:.4f}\")\n",
    "            print(f\"  ROUGE-L:     {val_metrics['rougeL']:.4f}\")\n",
    "            print(f\"  BERTScore:   {val_metrics['bertscore_f1']:.4f}\")\n",
    "            print(f\"  CIDEr:       {val_metrics['cider']:.4f}\")\n",
    "            print(f\"  Exact Match: {val_metrics['exact_match']:.4f}\")\n",
    "            \n",
    "            is_best = False\n",
    "            if composite_score > self.best_composite_score:\n",
    "                self.best_composite_score = composite_score\n",
    "                self.best_val_bleu = val_metrics['bleu']\n",
    "                self.best_val_loss = val_metrics['loss']\n",
    "                self.patience_counter = 0\n",
    "                is_best = True\n",
    "                print(f\"\\n✓ Model tốt nhất mới!\")\n",
    "                print(f\"  Composite: {composite_score:.4f}\")\n",
    "                print(f\"  BLEU:      {val_metrics['bleu']:.4f}\")\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                print(f\"\\n⚠ Không cải thiện ({self.patience_counter}/{self.config.PATIENCE})\")\n",
    "                print(f\"  Composite: {composite_score:.4f} (best: {self.best_composite_score:.4f})\")\n",
    "            \n",
    "            # Lưu checkpoint\n",
    "            self.save_checkpoint(epoch, val_metrics, is_best)\n",
    "            \n",
    "            # Sample predictions\n",
    "            print(f\"\\nVí dụ dự đoán:\")\n",
    "            for i in range(min(3, len(val_preds))):\n",
    "                print(f\"  GT:   {val_refs[i][:80]}\")\n",
    "                print(f\"  Pred: {val_preds[i][:80]}\\n\")\n",
    "            \n",
    "            print(\"=\"*60 + \"\\n\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= self.config.PATIENCE:\n",
    "                print(f\"Early stopping sau {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        # Lưu history\n",
    "        history = {\n",
    "            'train_losses': self.train_losses,\n",
    "            'val_losses': self.val_losses,\n",
    "            'val_metrics': self.val_metrics_history,\n",
    "            'best_composite_score': self.best_composite_score,  \n",
    "            'best_bleu': self.best_val_bleu\n",
    "        }\n",
    "        with open(os.path.join(self.config.OUTPUT_DIR, 'training_history.json'), 'w') as f:\n",
    "            json.dump(history, f, indent=2)\n",
    "        \n",
    "        return val_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================================================\n",
    "# 12. Main Function \n",
    "# ========================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ViT + PhoBERT + ViT5 với LoRA\")\n",
    "    print(\"Hệ thống VQA Di sản Việt Nam\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Khởi tạo tokenizers\n",
    "    print(\"Loading tokenizers...\")\n",
    "    segmenter = WordSegmenter()\n",
    "    vit_processor = ViTImageProcessor.from_pretrained(config.VIT_MODEL)\n",
    "    phobert_tokenizer = AutoTokenizer.from_pretrained(config.PHOBERT_MODEL)\n",
    "    vit5_tokenizer = AutoTokenizer.from_pretrained(config.VIT5_MODEL)\n",
    "    print(\"✓ Done\\n\")\n",
    "    \n",
    "    # Load dữ liệu\n",
    "    print(\"Loading dataset...\")\n",
    "    train_samples, val_samples, test_samples = load_and_prepare_data(\n",
    "        config.JSON_PATH, config.IMAGE_BASE_PATH\n",
    "    )\n",
    "    \n",
    "    # Tạo datasets\n",
    "    print(\"Tạo datasets...\")\n",
    "    train_dataset = HeritageVQADataset(\n",
    "        train_samples, vit_processor, phobert_tokenizer, vit5_tokenizer, segmenter\n",
    "    )\n",
    "    val_dataset = HeritageVQADataset(\n",
    "        val_samples, vit_processor, phobert_tokenizer, vit5_tokenizer, segmenter\n",
    "    )\n",
    "    test_dataset = HeritageVQADataset(\n",
    "        test_samples, vit_processor, phobert_tokenizer, vit5_tokenizer, segmenter\n",
    "    )\n",
    "    \n",
    "    # Tạo data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=True,\n",
    "        num_workers=config.NUM_WORKERS, \n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS, \n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=config.BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS, \n",
    "        collate_fn=collate_fn,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    print(\"✓ Done\\n\")\n",
    "    \n",
    "    # Khởi tạo model\n",
    "    model = ViTPhoBERTViT5Model(config)\n",
    "    \n",
    "    # Khởi tạo trainer\n",
    "    trainer = Trainer(model, train_loader, val_loader, vit5_tokenizer, config)\n",
    "    \n",
    "    # Huấn luyện\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Đánh giá trên test set...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    test_metrics, test_preds, test_refs, test_questions, test_images = trainer.evaluate(\n",
    "        test_loader, \n",
    "        desc='Testing',\n",
    "        return_details=True  \n",
    "    )\n",
    "    \n",
    "    print(\"\\nKẾT QUẢ CUỐI CÙNG:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"BLEU:        {test_metrics['bleu']:.4f}\")\n",
    "    print(f\"ROUGE-1:     {test_metrics['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2:     {test_metrics['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L:     {test_metrics['rougeL']:.4f}\")\n",
    "    print(f\"BERTScore:   {test_metrics['bertscore_f1']:.4f}\")\n",
    "    print(f\"CIDEr:       {test_metrics['cider']:.4f}\")\n",
    "    print(f\"Exact Match: {test_metrics['exact_match']:.4f}\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    test_results = {\n",
    "        'metrics': test_metrics,\n",
    "        'predictions': []\n",
    "    }\n",
    "    \n",
    "    for i, (pred, ref, question, image) in enumerate(zip(\n",
    "        test_preds, test_refs, test_questions, test_images\n",
    "    )):\n",
    "        # Lấy thông tin sample từ test_samples\n",
    "        sample_info = test_samples[i] if i < len(test_samples) else {}\n",
    "        \n",
    "        test_results['predictions'].append({\n",
    "            'index': i,\n",
    "            'image': image,\n",
    "            'question': question,\n",
    "            'prediction': pred,\n",
    "            'reference': ref,\n",
    "            'site_name': sample_info.get('site_name', ''),\n",
    "            'location': sample_info.get('location', '')\n",
    "        })\n",
    "    \n",
    "    # Lưu results\n",
    "    with open(os.path.join(config.OUTPUT_DIR, 'test_results.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(test_results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"✓ Đã lưu test results với cấu trúc đầy đủ\")\n",
    "    \n",
    "    # In một số ví dụ\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Một số ví dụ dự đoán:\")\n",
    "    print(\"=\"*60)\n",
    "    for i in range(min(5, len(test_preds))):\n",
    "        print(f\"\\n[{i+1}] Image: {test_images[i]}\")\n",
    "        print(f\"Question:   {test_questions[i]}\")\n",
    "        print(f\"Prediction: {test_preds[i]}\")\n",
    "        print(f\"Reference:  {test_refs[i]}\")\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    print(\"\\nHoàn thành huấn luyện!\")\n",
    "    print(f\"Kết quả lưu tại: {config.OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
